# Projeto de Redes Neurais e Machine Learning

Este projeto √© uma imers√£o em algoritmos cl√°ssicos de **machine learning** e redes neurais, com implementa√ß√µes detalhadas do **Perceptron**, **Adaline**, e uma explora√ß√£o do funcionamento de redes neurais modernas. Abaixo, descrevemos os conceitos t√©cnicos, matem√°tica subjacente e aplica√ß√µes pr√°ticas.

---

## üß† Conceitos Fundamentais

### 1. Machine Learning (ML)
- **Defini√ß√£o**: Capacidade de sistemas aprenderem padr√µes a partir de dados sem programa√ß√£o expl√≠cita.
- **Tipos**:
  - **Supervisionado**: Treinamento com pares (entrada, sa√≠da). Ex: Classifica√ß√£o, regress√£o.
  - **N√£o supervisionado**: Identifica√ß√£o de estruturas em dados n√£o rotulados. Ex: Clustering.
  - **Refor√ßo**: Aprendizado por intera√ß√£o e recompensa.

---

## üîç Perceptron: O Bloco B√°sico

### Vis√£o Geral
- Desenvolvido por Frank Rosenblatt (1957), √© a base para redes neurais.
- **Objetivo**: Classifica√ß√£o bin√°ria (ex: separar duas classes linearmente).

### Funcionamento Matem√°tico
1. **Entrada**: Vetor de caracter√≠sticas \( \mathbf{x} = [x_1, x_2, ..., x_n] \).
2. **Pesos**: \( \mathbf{w} = [w_1, w_2, ..., w_n] \) (inicializados aleatoriamente).
3. **Sa√≠da Bruta**: \( z = \mathbf{w} \cdot \mathbf{x} + b \) (bias: \( b \)).
4. **Fun√ß√£o de Ativa√ß√£o**: Degrau (Step Function):
   \[
   y_{\text{pred}} = 
   \begin{cases} 
   1 & \text{se } z \geq 0, \\
   0 & \text{se } z < 0.
   \end{cases}
   \]

### Atualiza√ß√£o dos Pesos
- **Regra de Aprendizado**: 
  \[
  \Delta w_i = \alpha \times (y_{\text{true}} - y_{\text{pred}}) \times x_i
  \]
  - \( \alpha \): Taxa de aprendizado (controla a magnitude da atualiza√ß√£o).
  - Itera√ß√£o at√© converg√™ncia ou m√°ximo de √©pocas.

### Limita√ß√µes
- S√≥ resolve problemas **linearmente separ√°veis**.
- N√£o lida com ru√≠dos ou dados n√£o lineares.

---

## üìà Adaline (Adaptive Linear Neuron)

### Evolu√ß√£o do Perceptron
- Introduzido por Bernard Widrow e Ted Hoff (1960).
- **Diferen√ßa Chave**: Minimiza uma fun√ß√£o de custo cont√≠nua (erro quadr√°tico) em vez de atualiza√ß√µes diretas.

### Funcionamento
1. **Sa√≠da Bruta**: \( z = \mathbf{w} \cdot \mathbf{x} + b \).
2. **Fun√ß√£o de Ativa√ß√£o**: Linear (identidade) para treinamento.
3. **Fun√ß√£o de Custo**: Erro Quadr√°tico M√©dio (MSE):
   \[
   J(\mathbf{w}) = \frac{1}{2} \sum_{i=1}^{m} (y_{\text{true}}^{(i)} - z^{(i)})^2
   \]

### Gradiente Descendente
- **Atualiza√ß√£o de Pesos**:
  \[
  \mathbf{w} := \mathbf{w} - \alpha \nabla J(\mathbf{w})
  \]
  - Gradiente calculado como:
    \[
    \nabla J(\mathbf{w}) = -\sum_{i=1}^{m} (y_{\text{true}}^{(i)} - z^{(i)}) \mathbf{x}^{(i)}
    \]

### Vantagens sobre o Perceptron
- Suaviza a fun√ß√£o de custo, permitindo converg√™ncia mais est√°vel.
- Pode ser estendido para problemas n√£o lineares com kernels.

---

## üöÄ Redes Neurais Modernas: Arquitetura e Treinamento

### Estrutura Hier√°rquica
1. **Camada de Entrada**: 
   - Neur√¥nios correspondem √†s features dos dados (ex: pixels em uma imagem).
2. **Camadas Ocultas**:
   - Extraem caracter√≠sticas intermedi√°rias (ex: bordas em vis√£o computacional).
3. **Camada de Sa√≠da**:
   - Neur√¥nios correspondem √†s classes ou valores preditos (ex: softmax para classifica√ß√£o).

### Neur√¥nio Artificial Moderno
- **Fun√ß√£o de Ativa√ß√£o**: 
  - **ReLU**: \( f(z) = \max(0, z) \) (evita vanishing gradient).
  - **Sigmoid**: \( f(z) = \frac{1}{1 + e^{-z}} \) (para probabilidades).
  - **Softmax**: Normaliza sa√≠das para distribui√ß√£o de probabilidade.

### Algoritmo de Treinamento
1. **Forward Propagation**:
   - C√°lculo da sa√≠da da rede: \( \hat{y} = f(\mathbf{W}^{(L)} \cdot f(\mathbf{W}^{(L-1)} \cdot ... f(\mathbf{W}^{(1)} \mathbf{x}))) \).
2. **Fun√ß√£o de Custo**:
   - **Cross-Entropy**: Para classifica√ß√£o.
     \[
     J = -\frac{1}{m} \sum_{i=1}^{m} \sum_{c=1}^{C} y_{c}^{(i)} \log(\hat{y}_{c}^{(i)})
     \]
   - **MSE**: Para regress√£o.
3. **Backpropagation**:
   - C√°lculo de gradientes usando a regra da cadeia:
     \[
     \frac{\partial J}{\partial w_{ij}^{(k)}} = \frac{\partial J}{\partial \hat{y}} \cdot \frac{\partial \hat{y}}{\partial z^{(k)}} \cdot \frac{\partial z^{(k)}}{\partial w_{ij}^{(k)}}
     \]
4. **Otimiza√ß√£o**:
   - **Adam**: Combina momentum e adapta√ß√£o de taxa de aprendizado.
   - **SGD com Momentum**: Acelera converg√™ncia em dire√ß√µes consistentes.

### T√©cnicas Avan√ßadas
- **Regulariza√ß√£o**:
  - **L1/L2**: Penaliza pesos grandes.
  - **Dropout**: Desativa neur√¥nios aleatoriamente durante o treino.
- **Batch Normalization**: Normaliza sa√≠das das camadas para acelerar treinamento.

---

## üìä Aplica√ß√µes do Projeto

### Implementa√ß√µes
1. **Perceptron**:
   - Classifica√ß√£o de dados sint√©ticos linearmente separ√°veis.
   - Visualiza√ß√£o da fronteira de decis√£o.
2. **Adaline**:
   - Regress√£o linear com gradiente descendente.
   - An√°lise de sensibilidade √† taxa de aprendizado.
3. **Redes Neurais**:
   - Classifica√ß√£o de MNIST ou Iris dataset com PyTorch/TensorFlow.
   - Experimentos com diferentes fun√ß√µes de ativa√ß√£o e otimizadores.

### An√°lise de Resultados
- **M√©tricas**:
  - Acur√°cia, Precis√£o, Recall, F1-Score.
  - Matriz de Confus√£o e Curva ROC.
- **Visualiza√ß√£o**:
  - Gr√°ficos de converg√™ncia (loss vs. √©poca).
  - Mapas de caracter√≠sticas em camadas ocultas.

---

## üîß Funcionamento B√°sico de uma Rede Neural Moderna (Exemplo)

```python
# Exemplo Simplificado em PyTorch
import torch.nn as nn

class NeuralNetwork(nn.Module):
    def __init__(self):
        super().__init__()
        self.layer1 = nn.Linear(784, 128)  # Input -> Hidden
        self.layer2 = nn.Linear(128, 10)    # Hidden -> Output
        self.relu = nn.ReLU()

    def forward(self, x):
        x = self.relu(self.layer1(x))
        x = self.layer2(x)
        return x

# Treinamento
model = NeuralNetwork()
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

for epoch in range(10):
    for data, labels in dataloader:
        outputs = model(data)
        loss = criterion(outputs, labels)
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
